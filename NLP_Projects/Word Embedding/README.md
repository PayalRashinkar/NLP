# Word Embedding

**Description:**

1. Designed a sentiment analysis pipeline utilizing Word2Vec embeddings (pretrained and custom-trained) for feature extraction and trained machine learning (Perceptron, SVM) and deep learning models (MLP, CNN) to classify reviews into binary and ternary sentiment classes.
   
2. Evaluated models using TF-IDF, pretrained Word2Vec, and custom Word2Vec features, achieving insights into their comparative effectiveness for text representation in sentiment classification.


**Skills:**
  Programming and Libraries: Python, Pandas, NumPy, Gensim, PyTorch (or TensorFlow/Keras), Scikit-learn
	Word Embedding: Pretrained Word2Vec (Google News vectors), custom Word2Vec training with Gensim
	Machine Learning: Perceptron, SVM, TF-IDF vectorization
	Deep Learning: Multilayer Perceptrons (MLP), Convolutional Neural Networks (CNN)
	Text Preprocessing: Data cleaning, stopword removal, lemmatization, padding/truncation for CNNs
	Performance Metrics: Accuracy evaluation for binary and ternary classification
	Tools: Jupyter Notebook, version control for reproducibility
